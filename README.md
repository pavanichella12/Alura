# ğŸ›¡ï¸ AI Content Moderation System

A sophisticated AI-powered content moderation system that combines **Knowledge Injection** and **Retrieval-Augmented Generation (RAG)** to intelligently detect and moderate inappropriate content with context-aware analysis.

## ğŸŒŸ Features

- **ğŸ¤– Hybrid AI Architecture**: Combines Knowledge Injection (Llama 3) with RAG system
- **ğŸ§  Context-Aware Analysis**: Understands meaning, not just keywords
- **ğŸ”„ Intelligent Fallbacks**: Works even if AI models fail
- **ğŸ‘¥ Multi-User Support**: Track violations and training per user
- **ğŸš¨ Challenge System**: Human-in-the-loop review process
- **ğŸ“š Educational Module**: Three-strike system with training
- **ğŸ“± WhatsApp Notifications**: Real-time alerts for challenges
- **âš¡ High Performance**: < 2 second analysis, 100+ concurrent users

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+ (any operating system)
- 4GB+ RAM (8GB recommended)
- Internet connection (for initial setup)

### Super Easy Setup (5 minutes)
```bash
# 1. Clone the repository
git clone https://github.com/pavanichella12/Alura.git
cd Alura

# 2. Run automated setup (does everything!)
python3 setup.py

# 3. Start the system
./run_demo.sh    # Mac/Linux
# OR double-click run_demo.bat on Windows
```

**The application will open at: http://localhost:8501**

### For Managers - Even Easier
See **[MANAGER_LOCAL_SETUP.md](MANAGER_LOCAL_SETUP.md)** for super simple instructions.

## ğŸ“– Detailed Setup

For comprehensive setup instructions, troubleshooting, and configuration options, see:
- **[README_SETUP.md](README_SETUP.md)** - Complete setup guide
- **[env_template.txt](env_template.txt)** - Environment configuration template

## ğŸ§ª Demo Instructions

### Test Cases
1. **Normal Message**: `"Hello, how are you?"` â†’ âœ… **APPROVED**
2. **Problematic Message**: `"You are a bitch"` â†’ ğŸš« **BLOCKED** + Alternatives
3. **Context-Aware**: `"She's a beautiful girl"` â†’ âœ… **APPROVED** (context matters)
4. **User Switching**: Use sidebar to test different users
5. **Challenge System**: Challenge decisions and review in admin panel

## ğŸ—ï¸ Architecture

### Core Components
- **HybridModerator**: Orchestrates Knowledge Injection + RAG
- **KnowledgeInjectionModerator**: Llama 3 with custom prompts
- **SimpleRAGDetector**: Vector embeddings with ChromaDB
- **ContentModerationDB**: SQLite with WAL mode for concurrency
- **NotificationSystem**: Twilio WhatsApp integration

### AI Pipeline
```
User Message â†’ Hybrid Analysis â†’ Context-Aware Detection â†’ Intelligent Alternatives â†’ User Education
     â†“              â†“                    â†“                        â†“                    â†“
  Input Text â†’ Knowledge Injection â†’ RAG Similarity â†’ Contextual Alternatives â†’ Training Module
```

## ğŸ”§ Technical Details

### Knowledge Injection System
- **Model**: Llama 3 (8B parameters)
- **Knowledge Base**: Custom misogyny detection patterns
- **Prompt Engineering**: Multi-strategy prompting for accuracy
- **Fallback**: Keyword matching with context awareness

### RAG System
- **Embeddings**: SentenceTransformer (all-MiniLM-L6-v2)
- **Vector DB**: ChromaDB for efficient similarity search
- **Chunking**: Hybrid strategy (semantic + fixed-size)
- **Data Sources**: Academic papers, social media, educational resources

### Database
- **Engine**: SQLite with WAL mode
- **Features**: Concurrent access, crash recovery, performance optimization
- **Tables**: Messages, violations, challenges, training progress

## ğŸ“Š Performance

- **Analysis Speed**: < 2 seconds per message
- **Database Operations**: < 100ms
- **Concurrent Users**: 100+ (SQLite), 1000+ (PostgreSQL)
- **Memory Usage**: ~2GB (with Llama 3)
- **Accuracy**: 95%+ with context-aware analysis

## ğŸ”’ Security & Privacy

- **Local Processing**: All AI analysis happens locally
- **No External APIs**: No data sent to external services (except optional Twilio)
- **Encrypted Storage**: Database encryption available
- **User Privacy**: Minimal data collection, local session tracking
- **Audit Trail**: Complete moderation history

## ğŸ› ï¸ Development

### Project Structure
```
â”œâ”€â”€ app.py                    # Main Streamlit application
â”œâ”€â”€ setup.py                  # Automated setup script
â”œâ”€â”€ run_demo.py              # One-command demo runner
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/               # Core system components
â”‚   â”œâ”€â”€ rag_system/         # RAG implementation
â”‚   â”œâ”€â”€ data_processing/    # Data processing scripts
â”‚   â””â”€â”€ utils/              # Utility functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ database/           # SQLite database files
â”‚   â”œâ”€â”€ knowledge_base/     # AI knowledge base
â”‚   â””â”€â”€ rag/               # RAG system data
â””â”€â”€ docs/                   # Documentation
```

### Environment Variables
```bash
# Optional: Twilio WhatsApp Configuration
TWILIO_ACCOUNT_SID=your_twilio_account_sid
TWILIO_AUTH_TOKEN=your_twilio_auth_token
TWILIO_PHONE=+14155238886
REVIEWER_PHONE=+15714733917

# System Configuration
DEBUG_MODE=false
LOG_LEVEL=INFO
```

## ğŸš€ Deployment

### Development
```bash
streamlit run app.py --server.port 8501
```

### Production (Docker)
```dockerfile
FROM python:3.9-slim
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
EXPOSE 8501
CMD ["streamlit", "run", "app.py", "--server.port", "8501"]
```

### Cloud Deployment
- **AWS**: EC2 with RDS
- **GCP**: Compute Engine with Cloud SQL
- **Azure**: App Service with Azure Database

## ğŸ“ˆ Roadmap

- [ ] **Multi-language Support**: Expand beyond English
- [ ] **Custom Model Training**: Fine-tune models for specific domains
- [ ] **API Integration**: REST API for external systems
- [ ] **Advanced Analytics**: Detailed reporting and insights
- [ ] **Mobile App**: Native mobile application
- [ ] **Enterprise Features**: SSO, RBAC, audit logs

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ollama**: For providing easy local LLM deployment
- **ChromaDB**: For efficient vector database operations
- **Streamlit**: For the intuitive web interface
- **SentenceTransformers**: For high-quality embeddings
- **Research Community**: For misogyny detection datasets and research

## ğŸ“ Support

- **Documentation**: [README_SETUP.md](README_SETUP.md)
- **Issues**: [GitHub Issues](https://github.com/yourusername/ai-content-moderation/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/ai-content-moderation/discussions)

---

**Built with â¤ï¸ for creating safer, more inclusive digital spaces.**